{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 門禁系統實作\n",
    "\n",
    "我們將在這個課程中，使用 Azure 臉部辨識的功能，實作門禁系統。  \n",
    "這個教學分成兩部分：\n",
    "1. 第一部分：說明如何使用 Azure 臉部辨識的功能，完成辨識是兩張人臉是否一樣的功能。門禁系統最重要的元件，就是辨識目前的人臉，是否為系統中所預先儲存好的人臉。也就是說，要能辨識出兩張照片中的人臉，是否為屬同一個人，即使這兩張照片是在不同的角度，光影環境下，依然是可以運作。\n",
    "2. 第二部分：第一部分所完成的功能，只是辨識兩張照片的人臉是否一致。但並沒有「人」的概念。這是說，系統只知道有「臉」，但沒有法子把「臉」關聯到「人」。在第二部分中，我們要把這部分補上。這樣系統才有法子識別出目前這位使用者的人臉，是否為系統中登錄合法的「人」。\n",
    "\n",
    "參考資料:\n",
    "- [微軟FACE API](https://westus.dev.cognitive.microsoft.com/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039523a)\n",
    "- [課程講義--臉部辨識實作](http://elearning.nkust.edu.tw/learn/path/SCORM_fetchResource.php)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 匯入相關套件\n",
    "import requests\n",
    "import json\n",
    "from io import BytesIO\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageFont"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "請依照前一講的內容，將金鑰，以及 url 填入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_key = ''\n",
    "face_api_detect_url = 'https://<xxxxxxx>.cognitiveservices.azure.com/face/v1.0/detect'\n",
    "face_api_verify_url = 'https://<xxxxxxx>.cognitiveservices.azure.com/face/v1.0/verify'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: 辨識兩張照片中的人臉是否是同一張臉\n",
    "\n",
    "請找兩張照片，人臉儘可能清晰，且屬於同一人。\n",
    "\n",
    "這裏以``劉若英``的照片為例。\n",
    "\n",
    "底下有 5 張照片，都是劉若英的照片。  \n",
    "我們使用 img1-img4 當作模型的訓練資料，以 img5 做為測試資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = 'https://www.rumtoast.com/wp-content/uploads/2019/02/%E8%9E%A2%E5%B9%95%E5%BF%AB%E7%85%A7-2019-02-19-%E4%B8%8B%E5%8D%885.10.29_meitu_1.jpg'\n",
    "img2 = 'https://lifestyle.etnet.com.hk/column/images/stories/72/2020/05/20200504lolo01.png'\n",
    "\n",
    "img3 = 'https://image.pttnews.cc/2018/04/11/cb4bcfe702/5d5f72667741987975c9005514ceaab5.jpg'\n",
    "img4 = 'https://imgs.gvm.com.tw/upload/gallery/20180601/44545_05.jpg'\n",
    "img5 = 'https://cdn2.ettoday.net/images/3586/d3586654.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將兩張照片送到 Azure 雲端，分別取得這兩張照片的 Faceid。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[{\"faceId\": \"288ce2ab-3c4e-4f6b-bed9-77be1180d695\", \"faceRectangle\": {\"top\": 140, \"left\": 478, \"width\": 175, \"height\": 175}}]\n288ce2ab-3c4e-4f6b-bed9-77be1180d695\n"
    }
   ],
   "source": [
    "#第一張照片\n",
    "headers = {'Ocp-Apim-Subscription-Key': subscription_key}\n",
    "#使用 recognition_02 的辨識模型，這個模型是 2019 年開發出來，比 recognition_01 有更精準的辨識度\n",
    "params = {\n",
    "    'returnFaceId': 'true',\n",
    "    'returnFaceLandmarks': 'false',\n",
    "    'recognitionModel':'recognition_02'\n",
    "}\n",
    "response = requests.post(face_api_detect_url, params=params,\n",
    "                         headers=headers, json={\"url\": img1})\n",
    "print(json.dumps(response.json()))\n",
    "#取得第一張照片的 faceid\n",
    "face = response.json()[0]\n",
    "faceid1 = face['faceId']\n",
    "print(faceid1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[{\"faceId\": \"6c44cb1b-c839-469b-884e-e2605bb4f154\", \"faceRectangle\": {\"top\": 77, \"left\": 286, \"width\": 108, \"height\": 108}}]\n6c44cb1b-c839-469b-884e-e2605bb4f154\n"
    }
   ],
   "source": [
    "#第二張照片\n",
    "headers = {'Ocp-Apim-Subscription-Key': subscription_key}\n",
    "\n",
    "params = {\n",
    "    'returnFaceId': 'true',\n",
    "    'returnFaceLandmarks': 'false',\n",
    "    'recognitionModel':'recognition_02'\n",
    "}\n",
    "response = requests.post(face_api_detect_url, params=params,\n",
    "                         headers=headers, json={\"url\": img2})\n",
    "print(json.dumps(response.json()))\n",
    "#取得第二張照片的 faceid\n",
    "face = response.json()[0]\n",
    "faceid2 = face['faceId']\n",
    "print(faceid2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用 verify 的功能，判定是否為一樣的人臉\n",
    "\n",
    "上面我們使用了 Azure 的 detect (偵測) 的功能，由照片中抓出人臉，並取得一個唯一的人臉 id。  \n",
    "接著我們使用 Azure 的 verify (辨識) 功能，判定兩張照片中的人臉，是否為同一張人臉。\n",
    "\n",
    "如同 detect 功能，verify 功能也對應到一個雲端的網址，其網址如下\n",
    "\n",
    "https://<端點>/face/v1.0/**verify**\n",
    "\n",
    "大家可以看到網址的最後面是 verify 字串，代表是要呼叫 verify 的功能。  \n",
    "如果把 verify 改為 detect，那就是要呼叫 detect 的功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{\"isIdentical\": true, \"confidence\": 0.87974}\n"
    }
   ],
   "source": [
    "# 設定要傳給雲端的參數\n",
    "headers = {'Ocp-Apim-Subscription-Key': subscription_key}\n",
    "params = {\n",
    "    'faceId1': faceid1,\n",
    "    'faceId2': faceid2\n",
    "}\n",
    "#記得呼叫 verify 的網址！\n",
    "body=json.dumps(params)\n",
    "\n",
    "response = requests.post(face_api_verify_url, headers=headers, data=body)\n",
    "print(json.dumps(response.json()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在上例中，這兩張照片中的人臉被視為同一張臉。  \n",
    "微軟 AI 模型的信心有 88%。\n",
    "\n",
    "如果使用 recognition_01 的模型的話，其信心只有 50% 出頭而已。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Par2: 建構門禁系統\n",
    "\n",
    "在第 2 部分中，我們要開始建構門禁系統。  \n",
    "門禁系統通常要辨識一組使用者。例如家庭的門禁系統通常會包含一群家人的人臉。  \n",
    "\n",
    "為了完成這個功能，我們要完成底下的步驟：  \n",
    "1. 建立人臉群組 (personGroupId)  \n",
    "2. 建立一位使用者 (person)  \n",
    "3. 將使用者加入群組中  \n",
    "4. 將人臉加入對應的使用者中 (這步驟中，一位使用者最多可以加入 248 張臉)  \n",
    "5. 訓練模型，使 Azure 可以將所有的人臉和對應的使用者關聯起來  \n",
    "6. 辨識  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立人臉群組\n",
    "\n",
    "[建立人臉群組的參考資料](https://westus.dev.cognitive.microsoft.com/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395244)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用者的群組名稱\n",
    "#給一個使用者群組的 id，長度最長為 64 個字元，只能包含小寫的英文字母，以及 - 或 _\n",
    "personGroupId = 'home3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<Response [200]>\n"
    }
   ],
   "source": [
    "face_api_personGroup_url = 'https://testiemfaceapi.cognitiveservices.azure.com/face/v1.0/persongroups/' + personGroupId\n",
    "\n",
    "headers = {'Ocp-Apim-Subscription-Key': subscription_key}\n",
    "\n",
    "# recognitionModel 代表辨識臉部所用的 AI 模型，微軟目前推薦 recognition_02。\n",
    "# 這是 2019 年開發出來的模型，其精確度較 recognition_01 這個舊的模型來得高。\n",
    "body = {\n",
    "    'name':'friends',\n",
    "    'recognitionModel':'recognition_02'\n",
    "}\n",
    "body1=json.dumps(body)\n",
    "\n",
    "response = requests.put(face_api_personGroup_url, headers=headers, data=body1)\n",
    "print(response)\n",
    "#print(json.dumps(response.json()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的程式碼若 response 為 200，代表成功地建立了群組"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立一位使用者，並將這位使用者加入群組中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_api_person_url = 'https://<xxxxxxx>.cognitiveservices.azure.com/face/v1.0/persongroups/' + personGroupId +'/persons'\n",
    "headers = {'Ocp-Apim-Subscription-Key': subscription_key}\n",
    "body = {\n",
    "    'name':'girl1'\n",
    "}\n",
    "body1=json.dumps(body)\n",
    "response = requests.post(face_api_person_url, headers=headers, data=body1)\n",
    "d1 = response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "99f0c79a-e865-45f8-97ca-568e95aa4ca1\n"
    }
   ],
   "source": [
    "#執行成功後，得到一個 personId。\n",
    "#這個 PersonId 是新加入使用者的唯一編號。\n",
    "\n",
    "personid = d1['personId']\n",
    "print(personid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 替使用者加入對應的臉部照片\n",
    "\n",
    "我們將 img1-img4 加入 girl1 這位使用者的照片庫中。  \n",
    "\n",
    "[加入臉部資料的文件](https://westus.dev.cognitive.microsoft.com/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039523b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{\"persistedFaceId\": \"c3e2b2fe-6239-4d63-8d8c-24ca1eae68c1\"}\n{\"persistedFaceId\": \"9b7dc194-1be6-47eb-ab81-acc5f6167557\"}\n{\"persistedFaceId\": \"77522957-a0eb-483d-8110-098be7c4b43a\"}\n{\"persistedFaceId\": \"af276813-2e6c-49f6-8167-2c3e91ea7148\"}\n"
    }
   ],
   "source": [
    "face_api_addface_url = 'https://<xxxxxxx>.cognitiveservices.azure.com/face/v1.0/persongroups/' + personGroupId +'/persons/'+personid+'/persistedFaces'\n",
    "headers = {'Ocp-Apim-Subscription-Key': subscription_key}\n",
    "#第一張臉\n",
    "response = requests.post(face_api_addface_url, headers=headers, json={'url':img1})\n",
    "face = json.dumps(response.json())\n",
    "print(face)\n",
    "#第二張臉\n",
    "response = requests.post(face_api_addface_url, headers=headers, json={'url':img2})\n",
    "face = json.dumps(response.json())\n",
    "print(face)\n",
    "#第三張臉\n",
    "response = requests.post(face_api_addface_url, headers=headers, json={'url':img3})\n",
    "face = json.dumps(response.json())\n",
    "print(face)\n",
    "#第四張臉\n",
    "response = requests.post(face_api_addface_url, headers=headers, json={'url':img4})\n",
    "face = json.dumps(response.json())\n",
    "print(face)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述的程式碼是可以用 for 迴圈完成！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練模型\n",
    "\n",
    "臉都加入後，就可以開始訓練模型了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<Response [202]>\n"
    }
   ],
   "source": [
    "face_api_train_url='https://<xxxxxxx>.cognitiveservices.azure.com/face/v1.0/persongroups/' + personGroupId +'/train'\n",
    "headers = {'Ocp-Apim-Subscription-Key': subscription_key}\n",
    "response = requests.post(face_api_train_url, headers=headers)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的程式碼要是回傳 202，表示 Azure 已經接受了你的要求。\n",
    "\n",
    "我們可以呼叫底下的程式碼，看看模型訓練好了沒？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{\"status\": \"succeeded\", \"createdDateTime\": \"2020-05-11T12:02:09.7551379Z\", \"lastActionDateTime\": \"2020-05-11T12:02:10.1272205Z\", \"message\": null, \"lastSuccessfulTrainingId\": \"df843044-07a3-481a-979e-56e76e323317\", \"lastSuccessfulTrainingDateTime\": \"2020-05-11T12:02:10.1272205Z\"}\n"
    }
   ],
   "source": [
    "face_api_training_url='https://<xxxxxxx>.cognitiveservices.azure.com/face/v1.0/persongroups/' + personGroupId +'/training'\n",
    "headers = {'Ocp-Apim-Subscription-Key': subscription_key}\n",
    "response = requests.get(face_api_training_url, headers=headers)\n",
    "print(json.dumps(response.json()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果上述的狀態是 successed，那表示完成訓練了。  \n",
    "如果是 running，表示還在訓練中。   \n",
    "如果是 notstarting，表示還沒開始。  \n",
    "如果是 failed，表示失敗。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[{\"faceId\": \"409e7f8b-4cef-484e-b6c9-00d24e7bd98d\", \"faceRectangle\": {\"top\": 68, \"left\": 308, \"width\": 109, \"height\": 109}}]\n409e7f8b-4cef-484e-b6c9-00d24e7bd98d\n"
    }
   ],
   "source": [
    "#第五張照片\n",
    "headers = {'Ocp-Apim-Subscription-Key': subscription_key}\n",
    "\n",
    "params = {\n",
    "    'returnFaceId': 'true',\n",
    "    'returnFaceLandmarks': 'false',\n",
    "    'recognitionModel':'recognition_02'\n",
    "}\n",
    "response = requests.post(face_api_detect_url, params=params,\n",
    "                         headers=headers, json={\"url\": img5})\n",
    "print(json.dumps(response.json()))\n",
    "#取得第一張照片的 faceid\n",
    "face = response.json()[0]\n",
    "faceid5 = face['faceId']\n",
    "print(faceid5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將第5張照片傳給雲端，並使用 Persongroup 來辨識，能不能辦識成功。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{\"isIdentical\": true, \"confidence\": 0.94516}\n"
    }
   ],
   "source": [
    "# 設定要傳給雲端的參數\n",
    "headers = {'Ocp-Apim-Subscription-Key': subscription_key}\n",
    "body = {\n",
    "    'faceId': faceid5,\n",
    "    'personGroupId': personGroupId,\n",
    "    'personId': personid\n",
    "}\n",
    "#記得呼叫 verify 的網址！\n",
    "body1=json.dumps(body)\n",
    "\n",
    "response = requests.post(face_api_verify_url, headers=headers, data=body1)\n",
    "print(json.dumps(response.json()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在上面的例子中，微軟的雲端模型有約 95% 的信心，這是群組中的人臉。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用另一張「非群組」中的人臉，看看微軟的判斷是如何？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[{\"faceId\": \"047219a7-c923-4c45-846e-ead6df42f3bc\", \"faceRectangle\": {\"top\": 210, \"left\": 429, \"width\": 271, \"height\": 271}}]\n047219a7-c923-4c45-846e-ead6df42f3bc\n"
    }
   ],
   "source": [
    "#第 6 張照片，使用于文文的照片\n",
    "img6 = 'https://images.chinatimes.com/newsphoto/2018-02-22/900/BBC200_P_04_02.jpg'\n",
    "headers = {'Ocp-Apim-Subscription-Key': subscription_key}\n",
    "\n",
    "params = {\n",
    "    'returnFaceId': 'true',\n",
    "    'returnFaceLandmarks': 'false',\n",
    "    'recognitionModel':'recognition_02'\n",
    "}\n",
    "response = requests.post(face_api_detect_url, params=params,\n",
    "                         headers=headers, json={\"url\": img6})\n",
    "print(json.dumps(response.json()))\n",
    "#取得第一張照片的 faceid\n",
    "face = response.json()[0]\n",
    "faceid6 = face['faceId']\n",
    "print(faceid6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{\"isIdentical\": false, \"confidence\": 0.09591}\n"
    }
   ],
   "source": [
    "# 設定要傳給雲端的參數\n",
    "headers = {'Ocp-Apim-Subscription-Key': subscription_key}\n",
    "body = {\n",
    "    'faceId': faceid6,\n",
    "    'personGroupId': personGroupId,\n",
    "    'personId': personid\n",
    "}\n",
    "#記得呼叫 verify 的網址！\n",
    "body1=json.dumps(body)\n",
    "\n",
    "response = requests.post(face_api_verify_url, headers=headers, data=body1)\n",
    "print(json.dumps(response.json()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由上述的結果可以看出，Azure 判斷這張照片中的人臉是不屬於群組中的人臉。  \n",
    "信心只有約 9%。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitconda72dd946d541e44749af55d5446157c12",
   "display_name": "Python 3.7.6 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}